{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Som-based strategy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configuring notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "from sklearn.model_selection import train_test_split, StratifiedShuffleSplit\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "from minisom import MiniSom"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define functions for SOM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_som(data, x_size, y_size):\n",
    "    \"\"\"Create SOM using the MiniSom library. Default parameters: learning rate is 0.1 and sigma is half of the highest dimension\"\"\"\n",
    "    \n",
    "    learning_rate = 0.1\n",
    "    sigma = max(x_size, y_size)*0.5\n",
    "\n",
    "    som = MiniSom(x_size, y_size, data.shape[1], \n",
    "                sigma=sigma, learning_rate=learning_rate, \n",
    "                neighborhood_function='gaussian')\n",
    "\n",
    "    return som"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def som_classification(som, data, class_assignments):\n",
    "    \"\"\"Classify examples as positive if they are close to positive examples in the topological map\"\"\"\n",
    "    prediction = []\n",
    "    for d in data:\n",
    "        winner = som.winner(d)\n",
    "        if isinstance(class_assignments[winner], list):\n",
    "            prediction.append(0)\n",
    "        else:\n",
    "            predicted = list(class_assignments[winner].keys())\n",
    "            prediction.append(int(1 in predicted))\n",
    "    \n",
    "    return prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiment setup\n",
    "This experiment takes an selectivity factor $f \\in [0.2, 0.5, 0.8]$ representing the percentage of data items the user provides in the examples. For instance, if the complete set of examples consists of $10$ data items, a selectivity factor $f = 0.2$ represents the case where the user provides only $2$ data items as examples.\n",
    "\n",
    "In this sense, the idea of this experiment is to verify whether the SOM technique can automatically select additional data items that are similar to the user-provided examples. Back to the previous example, we check whether the SOM could select data items in the complete set of examples composed by $10$ data items.\n",
    "\n",
    "#### SOM parameters\n",
    "In this experiment, we create a squared SOM with paramenters defined as follows:\n",
    "- Number of units (i.e., neurons): We use the rule described in [Documentation of the MATLAB SOM TOOLBOX](http://www.cis.hut.fi/projects/somtoolbox/documentation/somalg.shtml), that is, $M = 5\\cdot\\sqrt(N)$, where N is the number of training data instances.\n",
    "- Learning rate: 0.1\n",
    "- Sigma: Half of the highest dimension, that is, $\\sigma = max(x_{size}, y_{size})\\cdot 0.5$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def experiment(name_data, original_data, preprocessed_data, queries, nexperiments):\n",
    "    data = preprocessed_data.values\n",
    "    result = []\n",
    "    for query_id in range(len(queries)):\n",
    "        concept = original_data.query(queries[query_id]).index.to_list()\n",
    "        labels = [int(x in concept) for x in range(1, data.shape[0]+1)]\n",
    "\n",
    "        for factor_ex in [0.2, 0.5, 0.8]:\n",
    "            for i in range(nexperiments):\n",
    "                # Splitting traininig and test data\n",
    "                X_train, X_test, y_train, y_test = train_test_split(data, labels, test_size=factor_ex, stratify=labels)\n",
    "                \n",
    "                # Automatically selecting SOM size\n",
    "                num_neurons = 5*(data.shape[0]**0.543)\n",
    "                x_size = int(num_neurons**0.5) +1\n",
    "                y_size = int(num_neurons**0.5) +1\n",
    "                \n",
    "                som = create_som(data, x_size, y_size)\n",
    "                \n",
    "                # Initializing SOM weights\n",
    "                training_iterations = 1000\n",
    "                som.train_random(data, training_iterations, verbose=False)\n",
    "                \n",
    "                class_assignments = som.labels_map(X_train, y_train)\n",
    "                predicted = som_classification(som, X_test, class_assignments)\n",
    "                \n",
    "                # Evaluating results\n",
    "                scores = precision_recall_fscore_support(y_test, predicted, average='binary')\n",
    "                report = list(scores[:3]) + ['SOM', query_id, factor_ex]\n",
    "                result.append(report)\n",
    "       \n",
    "    df = pd.DataFrame(data=result, columns=['precision', 'recall', 'f1score', 'estimator', 'queryid', 'factorex'])\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data set: [1993 New Car Data](http://jse.amstat.org/datasets/93cars.txt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cartable = pd.read_pickle(os.path.join('datasets', 'car_original_dataset.pkl'))\n",
    "cartable.columns = [str.lower(col.replace('.', '_')) for col in cartable.columns]\n",
    "cartable['origin'] = cartable['origin'].map({0: False, 1: True})\n",
    "cartable['automatic_gearbox'] = cartable['automatic_gearbox'].map({0: False, 1: True})\n",
    "\n",
    "preprocessed_data = pd.read_pickle(os.path.join('datasets', '1993CarsPrep.pkl'))\n",
    "\n",
    "queries = [\n",
    "    \"type != 'Sporty' and origin == 1\",\n",
    "    \"automatic_gearbox == 1 and horsepower >= 150\",\n",
    "    \"price <= 7000 and mpg >= 26 and automatic_gearbox == 0\",\n",
    "    \"manufacturer == 'Ford' or manufacturer == 'Chevrolet'\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_exp = experiment('1993Cars', cartable, preprocessed_data, queries, nexperiments=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Checking results\n",
    "We show the average results collected during 10 experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_exp.query('estimator==\"SOM\"').groupby(['factorex']).mean()[['f1score', 'precision', 'recall']]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "",
   "version": "3.7.3-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
