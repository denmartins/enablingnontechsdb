{
 "cells": [
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Learning database queries via intelligent semiotic machines\n",
    "\n",
    "Publication information: Martins, D. M. L., Vossen, G., & de Lima Neto, F. B. (2017, November). Learning database queries via intelligent semiotic machines. In 2017 IEEE Latin American Conference on Computational Intelligence (LA-CCI) (pp. 1-6). IEEE.\n",
    "\n",
    "URL: https://ieeexplore.ieee.org/document/8285698\n",
    "\n",
    "Publication's BibTeX:\n",
    "\n",
    "```\n",
    "@INPROCEEDINGS{8285698,\n",
    "    author={D. M. L. {Martins} and G. {Vossen} and F. B. {de Lima Neto}},\n",
    "    booktitle={2017 IEEE Latin American Conference on Computational Intelligence (LA-CCI)},\n",
    "    title={Learning database queries via intelligent semiotic machines},\n",
    "    year={2017},\n",
    "    volume={},\n",
    "    number={},\n",
    "    pages={1-6},\n",
    "    keywords={Big Data;database management systems;information retrieval;learning (artificial intelligence);query languages;query processing;relational databases;SQL;SQL queries;database-specific knowledge;query language;database schema;intelligent semiotic machines;Big Data era;data-driven approaches;query criteria;hard constraints;information overload;Semiotics;Computational Intelligence techniques;tailored queries;data exploration;database search;data retrieval;database queries learning;information finding;Databases;Semiotics;Automobiles;Self-organizing feature maps;Neurons;Training;Electronic mail},\n",
    "    doi={10.1109/LA-CCI.2017.8285698},\n",
    "    ISSN={null},\n",
    "    month={Nov},\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Configuring notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os\n",
    "sys.path.append('..\\\\sada')\n",
    "sys.path.append('..\\\\decision')\n",
    "sys.path.append('..\\\\qbe')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datamanagement.dataaccessobject import DataAccessObject, Dataset\n",
    "from decision.somselector import SomSelector\n",
    "from sada.decisionsada import DecisionSADA\n",
    "from qbe.fitfunction import PersonalizedFitnessFunction\n",
    "from qbe.deapgpqbe import DEAPGeneticProgrammingQBE\n",
    "from qbe import util\n",
    "import pandas as pd, pandasql as pdsql\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import precision_recall_fscore_support"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Loading car dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DAO = DataAccessObject()\n",
    "dataset = DAO.get_car_dataset()\n",
    "dataset.preprocessed_data = pd.read_pickle(os.path.join('datasets', '1993CarsPrep.pkl'))"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Configuring SADA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sada = DecisionSADA(dataset, selector=SomSelector(som_size=(10,10), num_iterations=1024))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "concept = dataset.original_data.query('type==\"Sporty\" and Origin==0')\n",
    "print(concept.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = dataset.preprocessed_data\n",
    "y = [int(y in concept.index) for y in range(1, dataset.original_data.shape[0]+1)]"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Select an example index to start the learning process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "example_index = 33\n",
    "tuple_input = dataset.data_matrix[example_index].tolist()\n",
    "print(dataset.original_data.iloc[example_index])"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Selected examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_indexes = sada.select(query=tuple_input, num_of_selected_candidates=len(concept))\n",
    "print(selected_indexes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted = [int(i in selected_indexes) for i in range(dataset.original_data.shape[0])]"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Evaluating the quality of the SOM-based selection of Positive/Negative examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "precision_recall_fscore_support(y, predicted, average='binary')"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Query learning phase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fitnessfunc = PersonalizedFitnessFunction(X_train=X.values, y_train=predicted)\n",
    "query_learner = DEAPGeneticProgrammingQBE(X, fitnessfunc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_predicate = query_learner.simple_search(population_size=256, crossover_rate=0.9, mutation_rate=0.3, num_generations=50, max_gen_without_gain=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_predicate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.query(best_predicate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = len(set(X.query(best_predicate).index) & set(concept.index))/len(concept.index)\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Show retrieved data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "queries = [\"type == 'Sporty' and Origin == 0\", \n",
    "    \"type != 'Sporty' and Origin == 1\",\n",
    "    \"automatic_gearbox == 1 and horsepower >= 150\",\n",
    "    \"luggage_capacity >= 18 and passenger_capacity > 5\",\n",
    "    \"price <= 7000 and mpg >= 26 and automatic_gearbox == 0\",\n",
    "    \"manufacturer == 'Ford' or manufacturer == 'Chevrolet'\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "for q in queries:\n",
    "    concept = dataset.original_data.query(q)\n",
    "    y_test = [int(y in concept.index) for y in range(1, dataset.original_data.shape[0]+1)]\n",
    "    sada = DecisionSADA(dataset, selector=SomSelector(som_size=(10,10), num_iterations=dataset.original_data.shape[0]*10))\n",
    "    for i in range(10):\n",
    "        example_index = random.choice(concept.index)\n",
    "        tuple_input = dataset.data_matrix[example_index-1].tolist()\n",
    "        selected_indexes = sada.select(query=tuple_input,  num_of_selected_candidates=len(concept))\n",
    "        predicted = [int(i in selected_indexes) for i in range(dataset.original_data.shape[0])]\n",
    "        res = [q, len(concept.index)] + list(precision_recall_fscore_support(y_test, predicted, average='binary'))[:3]\n",
    "        results.append(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(results, columns=['query', 'concept size', 'precision', 'recall', 'f1score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby(by=['query', 'concept size']).mean().sort_values(by='f1score', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}