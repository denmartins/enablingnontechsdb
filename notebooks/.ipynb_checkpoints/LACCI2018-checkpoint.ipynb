{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import sys, os\n",
    "sys.path.append('..\\\\PhDCoding\\\\qbe')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np, pandas as pd, pandasql as pdsql, sklearn.datasets as ds\n",
    "import util\n",
    "from qbe.greedyqbe import GreedySearchQBE\n",
    "from qbe.fitfunction import QueryDiscoveryFitnessFunction\n",
    "from qbe.deapgpqbe import DEAPGeneticProgrammingQBE\n",
    "from qbe.treeqbe import DecisionTreeQBE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_results(predicate, dataframe, desired_set, undesired_set):\n",
    "    best_data_view = pysql(\"SELECT * FROM dataframe WHERE \" + predicate)\n",
    "    actual_set = util.convert_nparray_to_set(best_data_view)\n",
    "    recall = util.get_recall(actual_set, desired_set)\n",
    "    specificity = util.get_specificity(actual_set, desired_set, undesired_set)\n",
    "    length = 1 + predicate.split().count(\"AND\") + predicate.split().count(\"OR\")\n",
    "    return {'Recall': recall, 'Specificity': specificity, 'Length': length, 'Query': predicate}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def write_file_results(entry, filename):\n",
    "    with open('C:\\\\Users\\\\d_mart04.WIWI\\\\Downloads\\\\' + filename, 'a') as rfile:\n",
    "        rfile.write('{0};{1};{2};{3}'.format(entry['Recall'], entry['Specificity'], entry['Length'], entry['Query']))\n",
    "        rfile.write('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Loading the Iris dataset https://archive.ics.uci.edu/ml/datasets/iris\n",
    "iris = ds.load_iris()\n",
    "\n",
    "dataframe = pd.DataFrame(data= np.c_[iris['data'], iris['target']], columns= iris['feature_names'] + ['target'])\n",
    "\n",
    "dataframe.columns = [\"sepal_len\", \"sepal_wid\", \"petal_len\", \"petal_wid\", \"target\"]\n",
    "\n",
    "# Configure PandaSQL to query Pandas dataframe\n",
    "pysql = lambda q: pdsql.sqldf(q, globals())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiment 1: Discovering unknown queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def unknown_queries_discovery(dataframe, tuples_count):\n",
    "    filename = '_unkq_selectivity_{0}.txt'.format(tuples_count)\n",
    "    \n",
    "    size_desired_set = random.randint(1, tuples_count)\n",
    "    indices = [random.randint(0, dataframe.shape[0]-1) for x in range(size_desired_set)]\n",
    "    desired_output = dataframe.loc[indices]\n",
    "\n",
    "    total_set = util.convert_nparray_to_set(dataframe)\n",
    "    desired_set = util.convert_nparray_to_set(desired_output)\n",
    "    undesired_set = total_set - desired_set    \n",
    "    queryfitfunction = QueryDiscoveryFitnessFunction(dataframe, indices)\n",
    "\n",
    "    greedy_search = GreedySearchQBE(queryfitfunction, dataframe)\n",
    "    best_greedy = greedy_search.search_best_predicate(max_iterations=100, threshold=0.001, verbose=False)\n",
    "    greedy = get_results(best_greedy, dataframe, desired_set, undesired_set)\n",
    "\n",
    "    write_file_results(greedy, 'greedy' + filename)\n",
    "\n",
    "    decision_tree = DecisionTreeQBE(dataframe, indices)\n",
    "    best_tree = decision_tree.search_best_predicate()\n",
    "    tree = get_results(best_tree, dataframe, desired_set, undesired_set)\n",
    "\n",
    "    write_file_results(tree, 'tree' + filename)\n",
    "\n",
    "    genetic_programming = DEAPGeneticProgrammingQBE(dataframe, queryfitfunction)\n",
    "    best_genetic = genetic_programming.simple_search(population_size=200, crossover_rate=0.9, \n",
    "                                                            mutation_rate=0.5, num_generations=100, \n",
    "                                                            max_gen_without_gain=30, verbose=False)\n",
    "    gp = get_results(best_genetic, dataframe, desired_set, undesired_set)\n",
    "\n",
    "    write_file_results(gp, 'gp' + filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for experiment in range(10):\n",
    "    #unknown_queries_discovery(dataframe, tuples_count=1)\n",
    "    unknown_queries_discovery(dataframe, tuples_count=15)\n",
    "    #unknown_queries_discovery(dataframe, tuples_count=50)\n",
    "    #unknown_queries_discovery(dataframe, tuples_count=100)\n",
    "    \n",
    "print('Finished')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiment 2: Discovering alternative queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def alternative_query_discovery(dataframe, index_list):\n",
    "    selectivity = len(index_list)\n",
    "    filename = '_altq_selectivity_{0}.txt'.format(selectivity)\n",
    "\n",
    "    desired_output = dataframe.loc[index_list]\n",
    "    total_set = util.convert_nparray_to_set(dataframe)\n",
    "    desired_set = util.convert_nparray_to_set(desired_output)\n",
    "    undesired_set = total_set - desired_set\n",
    "\n",
    "    fitness_function = QueryDiscoveryFitnessFunction(dataframe, index_list)\n",
    "    \n",
    "    algorithm = GreedySearchQBE(fitness_function, dataframe)\n",
    "    best_predicate = algorithm.search_best_predicate(max_iterations=100, threshold=0.001, verbose=False)\n",
    "    results = get_results(best_predicate, dataframe, desired_set, undesired_set)\n",
    "    \n",
    "    write_file_results(results, 'greedy' + filename)\n",
    "\n",
    "    algorithm = DecisionTreeQBE(dataframe, index_list)\n",
    "    best_predicate = algorithm.search_best_predicate()\n",
    "    results = get_results(best_predicate, dataframe, desired_set, undesired_set)\n",
    "\n",
    "    write_file_results(results, 'tree' + filename)\n",
    "\n",
    "    algorithm = DEAPGeneticProgrammingQBE(dataframe, fitness_function)\n",
    "    best_predicate = algorithm.simple_search(population_size=200, crossover_rate=0.90, \n",
    "                                                            mutation_rate=0.50, num_generations=100, \n",
    "                                                            max_gen_without_gain=30, verbose=False)\n",
    "    results = get_results(best_predicate, dataframe, desired_set, undesired_set)\n",
    "    \n",
    "    write_file_results(results, 'gp' + filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_queries = [\"SELECT * FROM dataframe WHERE petal_len >= 4.0 AND petal_wid = 1.8 AND target = 1\",\n",
    "                    \"SELECT * FROM dataframe WHERE sepal_len > 6.5 AND petal_wid >= 1.3 AND petal_wid <= 1.9\",\n",
    "                    \"SELECT * FROM dataframe WHERE sepal_wid <> 3.0 AND petal_len <> 1.4\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for query in original_queries:\n",
    "    view = pysql(query)\n",
    "    indices = util.get_original_indexes_from_view(dataframe, view)\n",
    "            \n",
    "    for i in range(10):\n",
    "        alternative_query_discovery(dataframe, indices)\n",
    "\n",
    "print('Finished')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiment 3: Classification Rule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def discover_without_target_class(dataframe, index_list):\n",
    "    selectivity = len(index_list)\n",
    "    filename = '_altq_selectivity_100_15.txt'\n",
    "\n",
    "    desired_output = dataframe.loc[index_list]\n",
    "    total_set = util.convert_nparray_to_set(dataframe)\n",
    "    desired_set = util.convert_nparray_to_set(desired_output)\n",
    "    undesired_set = total_set - desired_set\n",
    "\n",
    "    fitness_function = QueryDiscoveryFitnessFunction(dataframe, index_list)\n",
    "    \n",
    "    algorithm = GreedySearchQBE(fitness_function, dataframe)\n",
    "    best_predicate = algorithm.search_best_predicate(max_iterations=100, threshold=0.001, verbose=False)\n",
    "    results = get_results(best_predicate, dataframe, desired_set, undesired_set)\n",
    "    \n",
    "    write_file_results(results, 'greedy' + filename)\n",
    "    \n",
    "    algorithm = DecisionTreeQBE(dataframe, index_list)\n",
    "    best_predicate = algorithm.search_best_predicate()\n",
    "    results = get_results(best_predicate, dataframe, desired_set, undesired_set)\n",
    "\n",
    "    write_file_results(results, 'tree' + filename)\n",
    "\n",
    "    algorithm = DEAPGeneticProgrammingQBE(dataframe, fitness_function)\n",
    "    best_predicate = algorithm.simple_search(population_size=200, crossover_rate=0.90, \n",
    "                                                            mutation_rate=0.50, num_generations=100, \n",
    "                                                            max_gen_without_gain=30, verbose=False)\n",
    "    results = get_results(best_predicate, dataframe, desired_set, undesired_set)\n",
    "\n",
    "    write_file_results(results, 'gp' + filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe = pd.DataFrame(data= iris['data'], columns= iris['feature_names'])\n",
    "\n",
    "dataframe.columns = [\"sepal_len\", \"sepal_wid\", \"petal_len\", \"petal_wid\"]\n",
    "\n",
    "# Configure PandaSQL to query Pandas dataframe\n",
    "pysql = lambda q: pdsql.sqldf(q, globals())\n",
    "\n",
    "indices = [x for x in range(50, 100)]\n",
    "[discover_without_target_class(dataframe, indices) for i in range(10)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiment CAR dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datamanagement.dataaccessobject import DataAccessObject, Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DAO = DataAccessObject()\n",
    "dataset = DAO.get_car_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe = dataset.preprocessed_data\n",
    "dataframe.columns = ['Price', 'MPG', 'NumOfCylinders', 'horsepower', 'FuelTankCapacity',\n",
    "       'RPM', 'Wheelbase', 'RearSeatRoom', 'Weight', 'AutomaticGearbox',\n",
    "       'PassengerCapacity', 'length', 'width', 'LuggageCapacity', 'Origin',\n",
    "       'Compact', 'Large', 'Midsize', 'Small', 'Sporty', 'Van', 'Acura',\n",
    "       'Audi', 'BMW', 'Buick', 'Cadillac', 'Chevrolet', 'Chrysler', 'Dodge',\n",
    "       'Eagle', 'Ford', 'Geo', 'Honda', 'Hyundai', 'Infiniti', 'Lexus',\n",
    "       'Lincoln', 'Mazda', 'MercedesBenz', 'Mercury', 'Mitsubishi', 'Nissan',\n",
    "       'Oldsmobile', 'Plymouth', 'Pontiac', 'Saab', 'Saturn', 'Subaru',\n",
    "       'Suzuki', 'Toyota', 'Volkswagen', 'Volvo', '4WD', 'Front', 'Rear',\n",
    "       'DriverPassenger', 'DriverOnly', 'NoAirBags']\n",
    "\n",
    "# Configure PandaSQL to query Pandas dataframe\n",
    "pysql = lambda q: pdsql.sqldf(q, globals())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[unknown_queries_discovery(dataframe, tuples_count=25) for x in range(10)]\n",
    "print('Finished')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
